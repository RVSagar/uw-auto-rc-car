{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import time\n",
    "\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, MaxPool2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization, LeakyReLU\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras import regularizers\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "import os\n",
    "import yaml\n",
    "import pickle\n",
    "from yaml import *\n",
    "\n",
    "import sklearn\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import cv2\n",
    "from cv2 import cvtColor, GaussianBlur, resize\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the Tensorflow/Keras versions and seeing if GPU is running\n",
    "import tensorflow as tf\n",
    "print(\"Tensorflow Version: \" + tf.__version__)\n",
    "print('Keras Version: ' + keras.__version__)\n",
    "print(\"Running on GPU:\", tf.test.is_built_with_cuda())\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "#Limiting GPU Memory to reduce overloading\n",
    "gpus= tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Folder Structure\n",
    "\n",
    "Below is the folder structure needed in the root of the notebook. The names with extensions (.png, .yaml, .ipynb) are files while the names without extensions are folders. The indentation is representative of the tree structure, if the strucutre is changed, make sure to change the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "root\n",
    "    -> data\n",
    "        -> allInputImages.png\n",
    "    -> info\n",
    "        -> allInputYamls.yaml\n",
    "    -> models\n",
    "        -> checkpoints\n",
    "        -> final\n",
    "    -> test\n",
    "        -> allValidationImages.png\n",
    "        -> allValidationYamls.yaml\n",
    "    -> Model Training.ipynb\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Function to create the lists of imagePaths and yamlData for the Machine Learning\n",
    "def creatingLists():\n",
    "    #Folders names data and info will need to be created in the root with the images fed into data and yamls into info\n",
    "    imagePath = 'data'\n",
    "    yamlPath = 'info'\n",
    "    \n",
    "    #List of paths\n",
    "    imageList = os.listdir(imagePath)\n",
    "    yamlList = os.listdir(yamlPath)\n",
    "    \n",
    "    imagePaths = []\n",
    "    yamlData = []\n",
    "    \n",
    "    processNum = 0\n",
    "    \n",
    "    #Adding Image path to List\n",
    "    for filename in sorted(imageList):\n",
    "        imagePaths.append(os.path.join(imagePath, filename))\n",
    "        processNum += 1\n",
    "        print(filename + '  ' + str(processNum))\n",
    "        \n",
    "    processNum = 0\n",
    "    \n",
    "    #Parsing through each yaml file and adding its content to the list (will initially take some time)\n",
    "    for filename in sorted(yamlList):\n",
    "        with open(os.path.join(yamlPath, filename)) as file:\n",
    "            yamlDataInput = yaml.safe_load(file)\n",
    "            yamlData.append(yamlDataInput)\n",
    "            processNum += 1\n",
    "            print(filename + '   ' + str(processNum))\n",
    "    \n",
    "    return imagePaths, yamlData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     9
    ]
   },
   "outputs": [],
   "source": [
    "#Function to save the created lists to avoid parsing through Yaml files every time on load\n",
    "def savingLists(listToSave, listName):\n",
    "    try:\n",
    "        #Saving Lists\n",
    "        with open(listName + \".txt\", 'wb') as f:\n",
    "            pickle.dump(listToSave, f)\n",
    "        print(listName + ' Saved!')\n",
    "    except:\n",
    "        print(listName + ' Failed to Save!')\n",
    "\n",
    "#Function to open the saved lists\n",
    "def openingLists(listName):\n",
    "    listToOpen = []\n",
    "    try:\n",
    "        #Loading Lists\n",
    "        with open(listName + \".txt\", 'rb') as f:\n",
    "            listToOpen = pickle.load(f)\n",
    "        print(listName + ' Opened!')        \n",
    "    except:\n",
    "        print(listName + ' Failed to Open!')\n",
    "\n",
    "    return listToOpen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Function to isolate a certain parameter in the Yaml data list and return a list of it\n",
    "def isolateYAML(yamlData, parameter):\n",
    "    yamlIsolate = []\n",
    "    for yamls in yamlData:\n",
    "        yamlIsolate.append(yamls[parameter])\n",
    "    \n",
    "    print(parameter + ' isolated')\n",
    "    \n",
    "    return yamlIsolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Function to process the list of images (feed in the imagePathList) and make sure to enter whether to invert the images or not\n",
    "def processImages(imageList, inverseSize):\n",
    "    \n",
    "    ImageArray = []\n",
    "    \n",
    "    index = 0\n",
    "    for image in imageList:\n",
    "        src = cv2.imread(image)\n",
    "        src = cv2.cvtColor(src, cv2.COLOR_RGB2YUV)\n",
    "        src = cv2.GaussianBlur(src, (3,3), 0)\n",
    "        \n",
    "        if inverseSize is False:\n",
    "            imageAppend = cv2.resize(src, (200,150))\n",
    "        else:\n",
    "            imageAppend = cv2.resize(src, (150,200))\n",
    "        \n",
    "        ImageArray.append(imageAppend)\n",
    "        index += 1\n",
    "        print(str(index) + \"  Images Processed\")\n",
    "    \n",
    "    \n",
    "    ImageArray = np.array(ImageArray)\n",
    "    \n",
    "    print(\"Shape of Images: \", ImageArray.shape)\n",
    "    \n",
    "    return ImageArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Function to split the dataset into train, test sets (Consider adding a cross-validation set)\n",
    "def trainTestSplit(imagePaths, yamlData, splitPercent):\n",
    "    trainX, testX, trainY, testY = train_test_split(imagePaths, yamlData, test_size = splitPercent)\n",
    "    print(\"Training Data: %d\\nValidation Data: %d\" % (len(trainX), len(testX)))\n",
    "    return trainX, testX, trainY, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Single Function to see how long the model training process takes, to use look at comment below\n",
    "    # start the training process with a variable startTime = time.perf_counter()\n",
    "    # end the training with runTime(startTime)\n",
    "def runTime(startTime):\n",
    "    currentTime = time.perf_counter()\n",
    "    hours = (int)((currentTime - startTime) / 3600)\n",
    "    minutes = (int)(((currentTime - startTime) - (3600 * hours)) / 60)\n",
    "    seconds = (int)((currentTime - startTime) - (3600 * hours) - (60 * minutes))\n",
    "    \n",
    "    print(\"\\n__Time__\", \"\\nHours:\", hours, \"\\nMinutes:\", minutes, \"\\nSeconds:\", seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definitions\n",
    "The functions below are different models, It is recommened to make modifications to a duplicate of a model instead of changes directly to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def nvidiaBaseModel():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(3, (5,5), strides=(2,2), input_shape= (200,150,3), activation='elu'))\n",
    "    \n",
    "    model.add(Conv2D(24, (5,5), strides=(2,2), activation='elu'))\n",
    "    \n",
    "    model.add(Conv2D(36, (5,5), strides=(2,2), activation='elu'))\n",
    "    \n",
    "    model.add(Conv2D(48, (3,3), strides=(2,2), activation='elu'))\n",
    "    \n",
    "    model.add(Conv2D(64, (3,3), strides=(2,2), activation='elu'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(1164, activation='elu'))\n",
    "    model.add(Dense(100, activation='elu'))\n",
    "    model.add(Dense(50, activation='elu'))\n",
    "    model.add(Dense(10, activation='elu'))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    optimizer = Adam(learning_rate=1e-5)\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    \n",
    "    print(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nvidiaBaseModel_Dropout():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(3, (5,5), strides=(2,2), input_shape= (200,150,3), activation='elu'))\n",
    "    model.add(Conv2D(24, (5,5), strides=(2,2), activation='elu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(36, (5,5), strides=(2,2), activation='elu'))\n",
    "    model.add(Conv2D(48, (3,3), strides=(2,2), activation='elu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(64, (3,3), strides=(2,2), activation='elu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(1164, activation='elu'))\n",
    "    model.add(Dense(100, activation='elu'))\n",
    "    model.add(Dense(50, activation='elu'))\n",
    "    model.add(Dense(10, activation='elu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    optimizer = Adam(learning_rate=1e-5)\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    \n",
    "    print(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def cifarBaseModel_DropoutMaxpool():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 150, 3)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    optimizer = Adam(learning_rate=1e-5)\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    \n",
    "    print(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def cifarBaseModel_DropoutMaxpoolElu():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 150, 3)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='elu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    optimizer = Adam(learning_rate=1e-5)\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    \n",
    "    print(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def nvidiaBaseModel_DenseSoftmax():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(3, (5,5), strides=(2,2), input_shape= (200,150,3), activation='elu'))\n",
    "    \n",
    "    model.add(Conv2D(24, (5,5), strides=(2,2), activation='elu'))\n",
    "    \n",
    "    model.add(Conv2D(36, (5,5), strides=(2,2), activation='elu'))\n",
    "    \n",
    "    model.add(Conv2D(48, (3,3), strides=(2,2), activation='elu'))\n",
    "    \n",
    "    model.add(Conv2D(64, (3,3), strides=(2,2), activation='elu'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(1164, activation='softmax'))\n",
    "    model.add(Dense(100, activation='softmax'))\n",
    "    model.add(Dense(50, activation='softmax'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    optimizer = Adam(learning_rate=1e-5)\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    \n",
    "    print(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def nvidiaBaseModel_DenseSoftmaxDropout():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(3, (5,5), strides=(2,2), input_shape= (640,480,3), activation='elu'))\n",
    "    \n",
    "    model.add(Conv2D(24, (5,5), strides=(2,2), activation='elu'))\n",
    "    \n",
    "    model.add(Conv2D(36, (5,5), strides=(2,2), activation='elu'))\n",
    "    \n",
    "    model.add(Conv2D(48, (3,3), strides=(2,2), activation='elu'))\n",
    "    modelel.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(64, (3,3), strides=(2,2), activation='elu'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(1164, activation='softmax'))\n",
    "    model.add(Dense(100, activation='softmax'))\n",
    "    model.add(Dense(50, activation='softmax'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    optimizer = Adam(learning_rate=1e-5)\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    \n",
    "    print(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def nvidiaBaseModel_DenseRelu():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(3, (5,5), strides=(2,2), input_shape= (200,150,3), activation='elu'))\n",
    "    \n",
    "    model.add(Conv2D(24, (5,5), strides=(2,2), activation='elu'))\n",
    "    \n",
    "    model.add(Conv2D(36, (5,5), strides=(2,2), activation='elu'))\n",
    "    \n",
    "    model.add(Conv2D(48, (3,3), strides=(2,2), activation='elu'))\n",
    "    \n",
    "    model.add(Conv2D(64, (3,3), strides=(2,2), activation='elu'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(1164, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    optimizer = Adam(learning_rate=1e-5)\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    \n",
    "    print(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def nvidiaBaseModel_DenseReluDropout():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(3, (5,5), strides=(2,2), input_shape= (200,150,3), activation='elu'))\n",
    "    \n",
    "    model.add(Conv2D(24, (5,5), strides=(2,2), activation='elu'))\n",
    "    \n",
    "    model.add(Conv2D(36, (5,5), strides=(2,2), activation='elu'))\n",
    "    \n",
    "    model.add(Conv2D(48, (3,3), strides=(2,2), activation='elu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(64, (3,3), strides=(2,2), activation='elu'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(1164, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    optimizer = Adam(learning_rate=1e-5)\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    \n",
    "    print(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def nvidiaBaseModel_FullRelu():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(3, (5,5), strides=(2,2), input_shape= (640,480,3), activation='relu'))\n",
    "    \n",
    "    model.add(Conv2D(24, (5,5), strides=(2,2), activation='relu'))\n",
    "    \n",
    "    model.add(Conv2D(36, (5,5), strides=(2,2), activation='relu'))\n",
    "    \n",
    "    model.add(Conv2D(48, (3,3), strides=(2,2), activation='relu'))\n",
    "    \n",
    "    model.add(Conv2D(64, (3,3), strides=(2,2), activation='relu'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(1164, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    optimizer = Adam(learning_rate=1e-5)\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    \n",
    "    print(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def nvidiaBaseModel_FullSigmoid():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(3, (5,5), strides=(2,2), input_shape= (640,480,3), activation='sigmoid'))\n",
    "    \n",
    "    model.add(Conv2D(24, (5,5), strides=(2,2), activation='sigmoid'))\n",
    "    \n",
    "    model.add(Conv2D(36, (5,5), strides=(2,2), activation='sigmoid'))\n",
    "    \n",
    "    model.add(Conv2D(48, (3,3), strides=(2,2), activation='sigmoid'))\n",
    "    \n",
    "    model.add(Conv2D(64, (3,3), strides=(2,2), activation='sigmoid'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(1164, activation='sigmoid'))\n",
    "    model.add(Dense(100, activation='sigmoid'))\n",
    "    model.add(Dense(50, activation='sigmoid'))\n",
    "    model.add(Dense(10, activation='sigmoid'))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    optimizer = Adam(learning_rate=1e-5)\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    \n",
    "    print(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def baseTransferModel():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (5, 5), input_shape=(200,150,3)))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    model.add(Conv2D(32, (5, 5)))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(32, (5, 5)))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    model.add(Dense(3, activation=None))\n",
    "    # compile model\n",
    "    opt = SGD(lr=0.01, momentum=0.9, clipnorm=1)\n",
    "    model.compile(optimizer=opt, loss='mse', metrics=['mse'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Be sure to have imagePaths and yamlData folders made in root\n",
    "imagePathsName = \"imagePaths\"\n",
    "yamlDataName = \"yamlData\"\n",
    "\n",
    "#Creating Lists of Images and Yaml Data (Run only once the first time yamlData is parsed, comment out afterwards)\n",
    "imagePaths, yamlData = creatingLists()\n",
    "\n",
    "#Saving the Images and Yaml Lists (Run only once the first time yamlData is parsed, comment out afterwards)\n",
    "savingLists(imagePaths, imagePathsName)\n",
    "savingLists(yamlData, yamlDataName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Opening Image and Yaml Data Lists (Instead of creating the lists everytime)\n",
    "imagePaths = openingLists(imagePathsName)\n",
    "yamlData = openingLists(yamlDataName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Isolate Yaml Properties\n",
    "yamlIsolateSteerAngle = isolateYAML(yamlData, 'steering_angle')\n",
    "yamlIsolateSteerCommand = isolateYAML(yamlData, 'steering_command')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Proccessing the images into the ImageData list (a list of image arrays)\n",
    "ImageData = processImages(imagePaths, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data into individual sets (Change the second input parameter into which list to compare the images to, the thrid parameter is the split%)\n",
    "trainX, testX, trainY, testY = trainTestSplit(ImageData, yamlIsolateSteerAngle, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Start Time definition\n",
    "startTime = time.perf_counter()\n",
    "\n",
    "#Modify these when running different models\n",
    "modelName = 'nvidiaBaseModel_Dropout'\n",
    "model = nvidiaBaseModel_Dropout()\n",
    "\n",
    "#The saving directory for the models (make sure to create a models folder with a checkpoints and final folder inside of them)\n",
    "modelOutputDirCheckpoint = os.path.join(os.getcwd(), 'models', 'checkpoints')\n",
    "modelOutputDirFinal = os.path.join(os.getcwd(), 'models', 'final')\n",
    "\n",
    "#Converting sets to arrays\n",
    "trainX = np.asarray(trainX)\n",
    "testX = np.asarray(testX)\n",
    "trainY = np.asarray(trainY)\n",
    "testY = np.asarray(testY)\n",
    "print('Model Done')\n",
    "\n",
    "#Model Variable definition\n",
    "batchSize = 64\n",
    "numEpochs = 10\n",
    "\n",
    "datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=False)\n",
    "itTrain = datagen.flow(trainX, trainY, batch_size=batchSize)\n",
    "steps = int(trainX.shape[0] / batchSize)\n",
    "\n",
    "#Checkpoints (incase crash while training)\n",
    "checkpointCallback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(modelOutputDirCheckpoint, modelName + '_NavigationCheck.h5'), verbose=1, save_best_only=True)\n",
    "print('Prerequisites done')\n",
    "\n",
    "#The model training\n",
    "history = model.fit_generator(itTrain,\n",
    "                              steps_per_epoch=steps,\n",
    "                              epochs=numEpochs,\n",
    "                              validation_data=(testX,testY),\n",
    "                              verbose=1,\n",
    "                              callbacks=[checkpointCallback])\n",
    "print('history done')\n",
    "\n",
    "#Saving the final model\n",
    "model.save(os.path.join(modelOutputDirFinal, modelName + '_NavigationFinal_' + 'BatchSize:' + str(batchSize) + '_Epochs:' + str(numEpochs) + '_.h5'))\n",
    "print('model saved')\n",
    "\n",
    "#See how long everything took to run\n",
    "runTime(startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some basic metrics on the model\n",
    "plt.plot(history.history['loss'], color='blue')\n",
    "plt.plot(history.history['val_loss'], color='red')\n",
    "plt.legend(['training loss', 'validation loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to predict the outut for a model based on input image (image is already processed as numpy array)\n",
    "def computeParams(image):\n",
    "    model = load_model(os.path.join(modelOutputDirFinal, modelName + '_NavigationFinal_' + 'BatchSize:' + str(batchSize) + '_Epochs:' + str(numEpochs) + '_.h5'))\n",
    "    params = model.predict(image)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Validation lists\n",
    "testPath = os.listdir('test')\n",
    "imageTestPathVal = []\n",
    "yamlTestPathVal = []\n",
    "\n",
    "numImages = 100\n",
    "\n",
    "indexing = 0;\n",
    "for file in sorted(testPath):\n",
    "    if indexing < (numImages*2):\n",
    "        if file.endswith('.png'):\n",
    "            imageTestPathVal.append(os.path.join('test', file))\n",
    "        if file.endswith('.yaml'):\n",
    "            yamlTestPathVal.append(os.path.join('test', file))\n",
    "        indexing += 1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print('Number of Images Loaded: ' + str(len(imageTestPathVal)))\n",
    "print('Number of Yamls Loaded: ' + str(len(yamlTestPathVal)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preping the Validation images\n",
    "imageTestVal = processImages(imageTestPathVal, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Creating lists on actual angles based on yaml files and predicted angles based on model for the validation set\n",
    "index = 0\n",
    "\n",
    "modelOutput = []\n",
    "actualAngle = []\n",
    "\n",
    "for index1 in range(len(imageTest)):\n",
    "    index2 = computeParams(imageTestVal)[[index1]]\n",
    "    for index3 in index2:\n",
    "        for index4 in index3:\n",
    "            print(index4)\n",
    "            modelOutput.append(index4)\n",
    "\n",
    "for filename in yamlTestPathVal:\n",
    "    with open(filename) as file:\n",
    "        yamlDataInput = yaml.safe_load(file)\n",
    "        print(yamlDataInput['steering_angle'])\n",
    "        actualAngle.append(yamlDataInput[\"steering_angle\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Graphing the Validation set Real vs Predicted\n",
    "plt.plot(modelOutput, color = 'orange')\n",
    "plt.plot(actualAngle, color = 'green')\n",
    "\n",
    "plt.legend(['Output', 'Real'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support\n",
    "Most of the important code is commented with its purpose and functionality. Feel free to make changes and run the model. \n",
    "\n",
    "To create the data, read through the instruction on the main github page README to get the docker enviornment running. Then after the **source devel/setup.bash** step, cd into src/road_dataset_generation/scripts (or wherever the generate_dataset.py file is), then run the **./generate_dataset.py** command. If you want a fresh dataset (clear old data), then type y, else n.\n",
    "\n",
    "Check out the link below for some additional information:\n",
    "https://towardsdatascience.com/deeppicar-part-5-lane-following-via-deep-learning-d93acdce6110\n",
    "\n",
    "If there are any more questions or comments, feel free to contact me via email at bishneet.singh@uwaterloo.ca or n2deshmu@uwaterloo.ca or via teams."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
